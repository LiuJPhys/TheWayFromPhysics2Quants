\contentsline {section}{\numberline {1}Gradient banits}{1}{section.1}
\contentsline {section}{\numberline {2}Markov Decision Process}{2}{section.2}
\contentsline {section}{\numberline {3}Dynamic programming}{4}{section.3}
\contentsline {subsection}{\numberline {3.1}Policy evaluation}{4}{subsection.3.1}
\contentsline {subsection}{\numberline {3.2}Policy iteration}{4}{subsection.3.2}
\contentsline {subsection}{\numberline {3.3}Practical implement}{5}{subsection.3.3}
\contentsline {section}{\numberline {4}Monte Carlo Methods}{6}{section.4}
\contentsline {subsection}{\numberline {4.1}On-policy}{6}{subsection.4.1}
\contentsline {subsection}{\numberline {4.2}Off-policy}{7}{subsection.4.2}
\contentsline {section}{\numberline {5}Temporal-Difference learning}{9}{section.5}
\contentsline {subsection}{\numberline {5.1}SARSA}{10}{subsection.5.1}
\contentsline {subsection}{\numberline {5.2}Q-learning}{11}{subsection.5.2}
\contentsline {section}{\numberline {6}Eligibility Traces}{11}{section.6}
\contentsline {subsection}{\numberline {6.1}Forward TD($\lambda $)}{12}{subsection.6.1}
\contentsline {subsection}{\numberline {6.2}Backward TD$(\lambda )$}{12}{subsection.6.2}
\contentsline {subsection}{\numberline {6.3}SARSA$(\lambda )$}{14}{subsection.6.3}
