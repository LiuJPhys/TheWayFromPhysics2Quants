\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{sutton2000policy}
\@writefile{toc}{\contentsline {section}{\numberline {1}Policy Gradient Methods for Reinforcement Learning with Function Approximation}{2}{section.1}\protected@file@percent }
\newlabel{eq:approx_q}{{1.19}{3}{Policy Gradient Methods for Reinforcement Learning with Function Approximation}{equation.1.19}{}}
\newlabel{eq: cons}{{1.20}{3}{Policy Gradient with Function Approximation}{equation.1.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Eligibility Traces}{4}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}On policy}{4}{subsection.2.1}\protected@file@percent }
\citation{NIPS2008_3626}
\citation{sutton2009fast}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Off policy}{5}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}GTD--gradient temporal difference}{5}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1} Policy gradient methods for reinforcement learning with function approximation}{5}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Fast Gradient-Descent Methods for Temporal-Difference Learning with Linear Function Approximation}{6}{subsection.3.2}\protected@file@percent }
\citation{maei2011gradient}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}GTD$(\lambda )$}{7}{subsection.3.3}\protected@file@percent }
\citation{degris2012off}
\@writefile{toc}{\contentsline {section}{\numberline {4}Off Policy Actor-Critic}{10}{section.4}\protected@file@percent }
\newlabel{eq:tabular1}{{4.15}{11}{Off Policy Actor-Critic}{equation.4.15}{}}
\citation{silver2014deterministic}
\@writefile{toc}{\contentsline {section}{\numberline {5}DDPG}{13}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Determinisitic Policy Gradient Algorithms}{13}{subsection.5.1}\protected@file@percent }
\citation{schulman2015trust}
\@writefile{toc}{\contentsline {section}{\numberline {6}TRPO}{16}{section.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The black curse is our true objective, and we optimize red lower bound in local blue region.}}{17}{figure.1}\protected@file@percent }
\newlabel{eq:TRPO_eta}{{6.2}{17}{TRPO}{equation.6.2}{}}
\newlabel{eq: TRPO_eta1}{{6.4}{17}{TRPO}{equation.6.4}{}}
\citation{schulman2017proximal}
\newlabel{th:TRPO_lowerbound}{{6.0.1}{18}{}{theorem.6.0.1}{}}
\newlabel{eq:TRPO_problem}{{6.10}{18}{TRPO}{equation.6.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}PPO}{18}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}clipped Surrogate Objective}{19}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}A3C}{19}{section.8}\protected@file@percent }
\bibstyle{unsrt}
\bibdata{RL}
\bibcite{sutton2000policy}{{1}{}{{}}{{}}}
\bibcite{NIPS2008_3626}{{2}{}{{}}{{}}}
\bibcite{sutton2009fast}{{3}{}{{}}{{}}}
\bibcite{maei2011gradient}{{4}{}{{}}{{}}}
\bibcite{degris2012off}{{5}{}{{}}{{}}}
\bibcite{silver2014deterministic}{{6}{}{{}}{{}}}
\bibcite{schulman2015trust}{{7}{}{{}}{{}}}
\bibcite{schulman2017proximal}{{8}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Lists of Proofs}{21}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Eligibility Traces}{21}{subsection.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.1}Equivalence between forward and backward}{21}{subsubsection.A.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}TRPO}{21}{subsection.A.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.1}Proof Th.\ref  {th:TRPO_lowerbound}}{21}{subsubsection.A.2.1}\protected@file@percent }
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\newlabel{lem: TRPO1}{{A.2.1}{22}{}{lemma.A.2.1}{}}
