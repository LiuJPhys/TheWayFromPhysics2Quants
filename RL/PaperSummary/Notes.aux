\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{sutton2000policy}
\@writefile{toc}{\contentsline {section}{\numberline {1}Policy Gradient Methods for Reinforcement Learning with Function Approximation}{1}{section.1}\protected@file@percent }
\newlabel{eq:approx_q}{{1.19}{3}{Policy Gradient Methods for Reinforcement Learning with Function Approximation}{equation.1.19}{}}
\newlabel{eq: cons}{{1.20}{3}{Policy Gradient with Function Approximation}{equation.1.20}{}}
\citation{NIPS2008_3626}
\@writefile{toc}{\contentsline {section}{\numberline {2}GTD--gradient temporal difference}{4}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1} Policy gradient methods for reinforcement learning with function approximation}{4}{subsection.2.1}\protected@file@percent }
\citation{sutton2009fast}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Fast Gradient-Descent Methods for Temporal-Difference Learning with Linear Function Approximation}{5}{subsection.2.2}\protected@file@percent }
\citation{maei2011gradient}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}GTD$(\lambda )$}{6}{subsection.2.3}\protected@file@percent }
\citation{degris2012off}
\@writefile{toc}{\contentsline {section}{\numberline {3}Off Policy Actor-Critic}{9}{section.3}\protected@file@percent }
\newlabel{eq:tabular1}{{3.15}{11}{Off Policy Actor-Critic}{equation.3.15}{}}
\citation{silver2014deterministic}
\@writefile{toc}{\contentsline {section}{\numberline {4}DDPG}{12}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Determinisitic Policy Gradient Algorithms}{12}{subsection.4.1}\protected@file@percent }
\citation{schulman2015trust}
\@writefile{toc}{\contentsline {section}{\numberline {5}TRPO}{15}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The black curse is our true objective, and we optimize red lower bound in local blue region.}}{16}{figure.1}\protected@file@percent }
\newlabel{eq:TRPO_eta}{{5.2}{16}{TRPO}{equation.5.2}{}}
\newlabel{eq: TRPO_eta1}{{5.4}{16}{TRPO}{equation.5.4}{}}
\citation{schulman2017proximal}
\newlabel{th:TRPO_lowerbound}{{5.0.1}{17}{}{theorem.5.0.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}PPO}{17}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}clipped Surrogate Objective}{18}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Asynchronous Methods for Deep Reinforcement Learning}{18}{section.7}\protected@file@percent }
\bibstyle{unsrt}
\bibdata{RL}
\bibcite{sutton2000policy}{{1}{}{{}}{{}}}
\bibcite{NIPS2008_3626}{{2}{}{{}}{{}}}
\bibcite{sutton2009fast}{{3}{}{{}}{{}}}
\bibcite{maei2011gradient}{{4}{}{{}}{{}}}
\bibcite{degris2012off}{{5}{}{{}}{{}}}
\bibcite{silver2014deterministic}{{6}{}{{}}{{}}}
\bibcite{schulman2015trust}{{7}{}{{}}{{}}}
\bibcite{schulman2017proximal}{{8}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Lists of Proofs}{20}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}TRPO}{20}{subsection.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.1}Proof Th.\ref  {th:TRPO_lowerbound}}{20}{subsubsection.A.1.1}\protected@file@percent }
\newlabel{lem: TRPO1}{{A.1.1}{20}{}{lemma.A.1.1}{}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
